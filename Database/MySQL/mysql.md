# MySQL

## 关系数据库三大范式

进行数据库设计时，应遵循三大范式：

- 第一范式：数据库表的每一列都是不可分割的基本数据项（对于地名，可以拆分成省份名、市名、区名、街道）

- 第二范式：在满足第一范式的前提下，每一行都要有唯一标识存在，非主键字段必须只依赖于主键，不能只依赖主键的部分（对于学生成绩，主键是学号和课程号，学分依赖课程号，姓名依赖学号）；造成了数据冗余、删除异常、插入异常和更新异常

- 第三范式：在满足第二范式的前提下，属性不依赖于其他非主属性，即不存在传递依赖（对于员工工资，工资依赖于等级，等级依赖于工号）；造成了数据冗余和更新异常

## 范式与反范式

没有冗余的数据库未必是最好的数据库，有时为了提高运行效率就必须降低范式标准，适当保留冗余数据，增加字段允许冗余，达到空间换时间的目的

- 范式优点：减少数据冗余，表更新体积小速度快

- 范式缺点：对于查询需要对多表进行关联；更难进行索引优化

- 反范式优点：减少表的关联；更好地进行索引优化

- 反范式缺点：存在数据冗余及数据维护异常，对数据修改需要更多的成本


## MySQL 架构

MySQL 分为接入层、服务层、存储引擎层、系统文件层

- 接入层：不同语言的客户端通过 mysql 的协议与 mysql 服务器进行连接通信，接入层进行权限验证、连接池管理、线程管理等

- 服务层包括 sql 解析器、sql 优化器、数据缓冲、缓存等

- 存储引擎是基于表的

- 系统文件层包括保存数据、索引、日志等

![dHdEQK.png](https://s1.ax1x.com/2020/08/29/dHdEQK.png)

## 连接器

连接器负责跟客户端建立链接、获取权限、维持和管理连接

客户端太久没响应，连接器就会自动断开了，默认时长为 8 小时；断开后重连的时候会报错，如果想再继续操作，就需要重连

如果使用长连接，则导致爆内存，因为执行过程中临时使用的内存是管理在连接对象里面的

正确做法：定期断开长连接；执行过一个占用内存比较大的查询后就断开连接

## 数据库索引

### 磁盘 IO 与预读

#### 磁盘 IO

磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分

寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在 5ms 以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘 7200 转，旋转延迟就是 1 / 120 / 2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。那么访问一次磁盘的时间，即一次磁盘 IO 的时间约等于 5 + 4.17 = 9ms左右

#### 预读

当一次 IO 时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内；当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到

每一次 IO 读取的数据我们称之为一页，一般为 4k 或 8k，也就是我们读取一页内的数据时候，实际上才发生了一次 IO，B+ 树的一个节点存储在一页内


### 索引

添加索引使得每次查找数据时的磁盘 IO 次数控制在一个很小的数量级，最好是常数数量级

索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息

索引的一个主要目的就是加快检索表中数据的方法，亦即能协助信息搜索者尽快的找到符合限制条件的记录 ID 的辅助数据结构

DB 在执行一条 Sql 语句的时候，默认的方式是根据搜索条件进行全表扫描，遇到匹配条件的就加入搜索结果集合。如果我们对某一字段增加索引，查询时就会先去索引列表中一次定位到特定值的行数，大大减少遍历匹配的行数，所以能明显增加查询的速度

优点：

- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性

- 可以大大加快数据的检索速度，这也是创建索引的最主要的原因

- 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义

- 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间

- 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能

缺点：

- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加

- 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间

原则：

- 在查询中很少使用或者参考的列不应该创建索引

- 只有很少数据值的列也不应该增加索引

- 定义为 text、image 和 bit 数据类型的列不应该增加索引

- 当修改性能远远大于检索性能时，不应该创建索引

- 使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省索引空间

- 尽量的扩展索引，不要新建索引

- 定义有外键的数据列一定要建立索引


实现：一般分为 B+ 树索引和哈希索引

- B+ 树是非线性结构，它的节点是天然有序的；hash 桶是线性结构，哈希表中多个数据在存储关系上是没有任务顺序关系的

- 哈希索引适合等值查询，无法进行范围查询和模糊查询；B+ 树索引可以进行等值、部分前缀、范围查询

- B+ 树索引其非叶子节点均为 key 值，叶子节点是 key-data 键值对，叶子节点前后相连且有序

- 哈希索引 O(1) 在速度上毋庸置疑要快于 B+ 树近似 O(logn)，但哈希索引速度不稳定，当某个键值存在大量重复时效率极差

- 哈希索引无法利用索引完成排序

- 哈希索引不支持多列联合索引的最左匹配规则

- 哈希索引存储行指针，并通过开链的方式解决冲突

- 哈希索引没办法避免回表查询，B+ 树在聚簇索引和索引覆盖的情况下可以只通过索引查询

### 索引存储

数据库索引都是存储在磁盘上的，当数据量比较大的时候，索引也会很大；当我们利用索引查询的时候，不能把索引全部加载到内存，只能逐一加载每个磁盘页，磁盘页即对应着索引树的节点

磁盘 IO 次数由树的高度决定，因此不适合使用 BST 存储索引，因此需要使用更加矮胖的树结构

## AVL 树、RB 树、B 树和 B+ 树 

大多数自平衡搜索树（如 AVL 树和 RB 树）都会假定所有数据都在主内存中，但我们必须考虑无法容纳在主内存中的大量数据。当键的数量很大时，将以块形式从磁盘读取数据，与主存储器访问时间相比，磁盘访问时间非常高。

### AVL 树

自平衡二叉搜索树，树中任一节点的两个子树的高度差最大为 1，其查找、插入和删除在平均和最坏情况下的时间复杂度都是 O(log n)

- 具有二叉查找树的特点(左子树任一节点小于父节点，右子树任一节点大于父节点)，任何一个节点的左子树与右子树都是平衡二叉树

- 任一节点的左右子树高度差小于 1

AVL 树通过旋转来调整平衡

### RB 树

AVL 树比红黑树更加平衡，但 AVL 树可能在插入和删除过程中引起更多旋转；如果频繁的插入和删除，应首选 RB 树；如果插入和删除操作的频率较低，而搜索操作的频率较高，则 AVL 树应优先于红黑树

### B 树

#### 定义

B 树叫平衡多路查找树，设计的主要思想是减少磁盘访问次数，大多数树操作(增、删、查、最大值、最小值等)都需要都需要 O(h) 磁盘访问，h 为树的高度。

通常，B 树节点的大小保持与磁盘块大小相等，由于 B 树的高度较低，因此与平衡的二叉搜索树（如AVL 树、RB 树等）相比，大多数操作的磁盘访问次数显著减少。

先定义一条数据记录为一个二元组 [key, data]，key 为记录的键值，对于不同数据记录，key 是互不相同的；data 为数据记录除 key 外的数据

- M 阶 B 树表示每个节点最多 M 个子树

- 每个非叶子节点由 n-1 个 key 和 n 个指针组成，其中 M/2 <= n <= M，其中 M/2 向上取整

- 每个叶子节点最少包含一个 key 和两个指针，最多包含 M-1 个 key 和 M 个指针，叶节点的指针均为 null

- 所有叶子节点都在同一层

- key 和指针互相间隔，节点两端是指针

- 一个节点中的 key 从左到右非递减排列

- 每个指针要么为 null，要么指向另外一个节点

- 如果某个指针在节点 node 最左边且不为 null，则其指向节点的所有 key 小于 v_key1，其中 v_key1 为 node 的第一个 key 的值

- 如果某个指针在节点 node 最右边且不为 null，则其指向节点的所有 key 大于 v_key2，其中 v_key2 为 node 的最后一个 key 的值

- 如果某个指针在节点 node 的左右相邻 key 分别是 key_i 和 key_i+1 且不为 null，则其指向节点的所有 key 小于 v_key_i+1 且大于 v_key_i

- 每个节点都存储数据

一颗 4 阶的 B 树，每个节点最多有 4 个子树、3 个 key，最少有 2 个子树、1 个 key

![d4zmE4.png](https://s1.ax1x.com/2020/08/27/d4zmE4.png)

#### 插入保持平衡


- 首先考虑要插入的子树是否已经超出了关键字数的限制

- 超出的话，如果要插入的位置是叶子节点，就只能拆一个关键字添加到要插入位置的父节点

- 如果非叶子节点，就得从其他子树拆子树给新插入的元素做孩子

#### 删除保持平衡

删除孩子后，父节点是否还满足子树 k 介于 M/2 和 M 的条件，不满足就得从别的节点拆子树甚至修改相关子树结构来保持平衡

#### 性质

由于 B-Tree 的特性，在 B-Tree 中按 key 检索数据流程：首先从根节点进行二分查找，如果找到则返回对应节点的 data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到 null 指针，前者查找成功，后者查找失败

B 树的树内存储数据，因此查询单条数据的时候，B 树的查询效率不固定，最好的情况是 O(1)，所以做单一数据查询的时候，使用 B 树平均性能更好，在特定数据重复多次查询的场景中更加高效

由于 B 树中各节点之间没有指针相邻，因此 B 树不适合做一些数据遍历操作

### B+ 树

与 B-Tree 相比，B+Tree 有以下不同点：

- n 个 key 对应 n 个指针 n 颗树，M/2 <= n <= M

- 非叶子节点不存储 data，只存储 key；叶子节点不存储指针

- 所有叶子节点增加了一个链指针

![d5S5Yd.png](https://s1.ax1x.com/2020/08/27/d5S5Yd.png)

B+ 树的数据只出现在叶子节点上，因此在查询单条数据的时候，查询速度非常稳定，所以在做单一数据的查询上，其平均性能并不如 B 树

B+ 树的叶子节点上有指针进行相连，因此在做数据遍历的时候，只需要对叶子节点进行遍历即可，这个特性使得 B+ 树非常适合做范围查询

### 选择 B+ 树

- B 树只适合随机检索，而 B+ 树同时支持随机检索和顺序检索

- B+ 树空间利用率更高，可减少 IO 次数，磁盘读写代价更低：B+ 树内部结点比 B 树小，一次性读入内存中可以查找的关键字也就越多，从而 IO 次数降低了

- B+ 树的查询效率更加稳定

- 增删节点时，效率更高


## 索引类型

- 主键索引：数据列不允许重复，不允许为 NULL，一个表只能有一个主键

- 唯一索引：数据列不允许重复，允许为 NULL 值，一个表允许多个列创建唯一索引

- 普通索引: 基本的索引类型，没有唯一性的限制，允许为 NULL 值

- 全文索引：基于相似度的查询，而不是原来的精确数值比较；`like + %` 在文本比较少时是合适的，但是对于大量的文本数据检索，是不可想象的；全文索引可能存在精度问题


## 聚簇索引和非聚簇索引

InnoDB 的 B+ Tree 可能存储的是整行数据，也有可能是主键的值

聚簇索引：在 InnoDB 里，索引 B+ Tree 的叶子节点存储了整行数据的是主键索引

非聚簇索引：索引 B+ Tree 的叶子节点存储了主键的值的是非主键索引

聚簇索引查询会更快，因为主键索引树的叶子节点直接就是我们要查询的整行数据了，而非主键索引的叶子节点是主键的值，查到主键的值以后，还需要再通过主键的值回表查询

## 非主键索引存储的是主键索引值

非主键索引直接存储数据的地址，会带来一些问题：

1. 数据库备份、迁移困难

2. 插入、删除数据时，B+ 树可能发生分裂，导致物理地址变化

3. 无法给物理地址加行级锁

## 覆盖索引

非主键索引并不一定都会回表查询

索引覆盖：当一个查询语句的执行只用从索引中就能够取得，则不必从数据表中读取

常见方法：对被查询的字段建立联合索引

## 联合索引和最左前缀匹配

### 联合索引

在创建多列索引时，根据业务需求，where 子句中使用最频繁的一列放在最左边，因为 MySQL 索引查询会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。

当创建一个联合索引的时候，如 (key1,key2,key3)，相当于创建了 (key1)、(key1,key2) 和 (key1,key2,key3) 三个索引

= 和 in 可以乱序，查询优化器会帮你优化成索引可以识别的形式

### 最左前缀匹配

匹配时会一直向右匹配直到遇到范围查询，范围列可以用到索引，但是范围列后面的列无法用到索引，即索引最多用于一个范围列，如果查询条件中有两个范围列则无法全用到索引

like 语句中通配符出现在开头则不能使用索引

如果查询条件中含有函数或表达式，将导致索引失效而进行全表扫描

只要列中包含有 NULL 值都将不会被包含在索引中，复合索引中只要有一列含有 NULL 值，那么这一列对于此复合索引就是无效的

## 索引使用场景

- 查询时，加速 SQL 执行效率

- 如果没有创建索引，排序时将查询出的所有数据使用外部排序（将数据从硬盘分批读取到内存使用内部排序，最后合并排序结果），非常影响性能；建立索引后，数据本身有序，可直接按照索引的顺序和映射关系逐条取出数据

- 提高 join 效率

- 索引覆盖

## 索引失效

- 如果查询条件用 or，必须 or 条件中的每个列都加上索引，否则无效

- 违反最左匹配原则，则不适用索引

- like 语句中通配符出现在开头则不能使用索引

- 存在索引列的数据类型隐形转换，则不使用索引

- where 字句里对索引列有数学运算或者使用函数，则不使用索引

- mysql 优化器觉得全表扫描更快时，则不适用索引


## 百万级别的数据删除

索引文件是单独存在的文件，所以当我们对数据的增加、修改、删除，都会产生额外的对索引文件的操作，这些操作需要消耗额外的 IO，会降低增改删的执行效率

在删除数据库百万级别数据的时候，删除数据的速度和创建的索引数量是成正比的

1. 先删除索引

2. 删除数据

3. 重新创建索引

## 堆表和索引表

像 MyISAM 这样以堆形式存储数据的我们通常把它叫做堆表（HOT），像 InnoDB 这种将数据保存在叶子节点中叫做索引组织表（IOT）

## 事务

事务是一个不可分割的数据库操作序列，要么完全地执行，要么完全地不执行，是数据库并发控制得基本单位

事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源

通过将一组相关操作组合为一个要么全部成功要么全部失败的单元，可以简化错误恢复并使应用程序更加可靠

一个逻辑工作单元要成为事务，必须满足所谓的 ACID（原子性、一致性、隔离性和持久性）属性

- 原子性（Atomicity）：原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚

- 一致性（Consistency）：一致性规定了事务提交前后，永远只可能存在事务提交前的状态和事务提交后的状态，从一个一致性的状态到另一个一致性状态，而不可能出现中间的过程态；事务的执行结果是量子化状态，而不是线性状态

- 隔离性（Isolation）：当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务不能被其他事务的操作所干扰，多个并发事务之间要相互隔离；多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果；当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间

- 持久性（Durability）：持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作


## 数据库并发操作带来的一致性问题

数据库事物无非两种：读取事物、修改事物

在没有事务隔离控制的时候，多个事务在同一时刻对同一数据的操作可能就会影响到最终期望的结果，通常有四种情况：

- 脏写：一个事务的更新覆盖了另一个事务还没提交的更新（事务 A和 B 读入同一数据并修改，B 提交的结果破坏了 A 提交的结果，导致 A 的修改被丢失）

- 脏读：一个事务读取了另一个事物未提交的数据（事务 A 修改某一数据，并将其写回磁盘，事务 B 读取同一数据后，A 由于某种原因被撤销，这时 A 已修改过的数据恢复原值，B 读到的数据就与数据库中的数据不一致，则 B 读到的数据为脏数据）

- 不可重复读：一个事务两次读取同一个数据，两次读取的数据不一致（事务 A 读取某一数据后，事务 B 对其作了修改，当事务 A 再次读取数据时，得到与前一次不同的值；事务 A 按一定的条件从数据库中读取了某些数据后，事务 B 删除了其中部分记录，当 A 再次以相同条件读取时，发现某些记录消失了）

- 幻读：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据

幻读和不可重复读都是读取了另一条已经提交的事务（这点和脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体


## 事务隔离级别

同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰

- 未提交读 READ UNCOMMITTED：最低的隔离级别，一个事务在提交之前，对其他事务是可见的，即事务可以读取未提交的数据；存在脏读（读到了脏数据）问题

- 提交读 READ COMMITTED：事务在提交之前，对其它事务是不可见的；解决了脏读的问题，但存在不可重复读（两次查询的得到的结果可能不同，即可能在查询的间隙，有事务提交了修改）问题

- 可重复读 REPEATABLE READ：默认隔离等级，在同一事务中多次读取的数据是一致的；解决了脏读和不可重复读问题，存在幻读（在事务两次查询间隙，有其他事务又插入或删除了新的记录）问题

- 可串行化 SERIALIZABLE：通过对每个读的数据行加上共享锁，强制事务串行化执行，即一个事务一个事务挨个来执行，可以解决上述所有问题，隔离级别最高，牺牲了系统的并发性；可以解决并发事务的所有问题


## MVCC

MVCC 是一种多版本读写并发控制机制，是 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现 READ COMMIITTED 和 REPEATABLE READ 这两种隔离级别

MVCC 通过保存数据在某个时间点的快照来实现的；每行数据都存在一个版本，对数据库的任何修改的提交都不会直接覆盖之前的数据，而是产生一个新的版本与老版本共存，使得读取时可以不加锁（除非使用 `SELECT ... FOR UPDATE` 强行加锁）

- 通过 MVCC 可以让读写互相不阻塞，读不相互阻塞，写不阻塞读，这样可以提升数据并发处理能力

- 降低了死锁的概率，因为 MVCC 采用了乐观锁的方式，读取数据时，不需要加锁，写操作，只需要锁定必要的行

- 解决了一致性读的问题，MVCC 都是快照读，只能看到这个时间点之前事务提交更新的结果，不能看到时间点之后事务提交的更新结果

### 事务版本号

每次事务开启前都会从数据库获得一个自增长的事务 ID，可以从事务 ID 判断事务的执行先后顺序

### Undo log

Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到 Undo log 里，当事务进行回滚时可以通过 Undo log 里的日志进行数据还原

- 保证事务进行 rollback 时的原子性和一致性，当事务进行回滚的时候可以用 Undo log 的数据进行恢复

- 通过读取 Undo log 的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本

存储数据表的 B+ 树节点总是只保留最新的数据，而老版本的数据被放在 Undo log 里，并且以指针的形式关联起来，形成一个链表；查询时会在 B+ 树查找后多引入一个链表查询，但是清理废弃数据时会比较简单，只要把 Undo log 找到一个合适的位置一刀切了即可

### 隐藏字段

MySQL 会为每一行真实数据记录添加两三个隐藏的字段，分别为 row_id、transaction_id 和 roll_pointer

- row_id：非必需隐藏字段；如果表中有自定义的主键或者有 Unique 键，就不会添加 row_id 字段，如果两者都没有，MySQL 会自动添加 row_id 字段

- transaction_id：必需隐藏字段；代表这一行数据由哪个事务 id 创建

- roll_pointer：必需隐藏字段；回滚指针，指向这行数据上一个版本在 Undo log 的地址

![wSwOxO.png](https://s1.ax1x.com/2020/09/02/wSwOxO.png)

对于事务 id，只有执行 insert/update/delete 才会产生事务 id，只执行 select 则没有事务 id

![wS0lWV.png](https://s1.ax1x.com/2020/09/02/wS0lWV.png)

### ReadView 

READ COMMITTED 和 REPEATABLE READ 这两个事务隔离级别都要保证读到的数据是其他事务已经提交的，但是还是有一定的区别，最核心的问题就在于到底可以读取这个数据的哪个版本

ReadView 机制只在 Read Committed 和 Repeatable Read 隔离级别下生效，所以只有这两种隔离级别才有 MVCC

#### ReadView 组成

ReadView 包含四个比较重要的内容：

- m_ids：表示在生成 ReadView 时，系统中活跃的事务 id 集合

- min_trx_id：表示在生成 ReadView 时，系统中活跃的最小事务 id，也就是 m_ids 中的最小值

- max_trx_id：表示在生成 ReadView 时，系统应该分配给下一个事务的 id

- creator_trx_id：表示生成该 ReadView 的事务 id

#### ReadView 用法

有了 ReadView，根据相关信息则可以判断版本信息：

- 如果被访问的版本的 trx_id 和 ReadView 中的 creator_trx_id 相同，就意味着当前版本就是由当前事务创建的，可以读出来

- 如果被访问的版本的 trx_id 小于 ReadView 中的 min_trx_id，表示生成该版本的事务在创建 ReadView 的时候已经提交了，所以该版本可以读出来

- 如果被访问版本的 trx_id 大于或等于 ReadView 中的 max_trx_id 值，说明生成该版本的事务在当前事务生成 ReadView 后才开启，所以该版本不可以被读出来

- 如果生成被访问版本的 trx_id 在 min_trx_id 和 max_trx_id 之间，那就需要判断下 trx_id 在不在 m_ids 中；如果在，说明创建 ReadView 的时候，生成该版本的事务还是活跃的（没有被提交），该版本不可以被读出来；如果不在，说明创建 ReadView 的时候，生成该版本的事务已经被提交了，该版本可以被读出来

- 如果某个数据的最新版本不可以被读出来，就顺着 roll_pointer 找到该数据的上一个版本，继续做如上的判断

#### READ COMMITTED

每次读取数据都会创建 ReadView

#### REPEATABLE READ

首次读取数据会创建 ReadView


## 快照读和当前读

### 快照读

在 READ COMMITTED 和 REPEATABLE READ 隔离级别下，普通的 SELECT 查询都是读取 MVCC 版本链中的一个版本，相当于读取一个快照，因此称为快照读；这种读取方式不会加锁，因此读操作时非阻塞的，因此也叫非阻塞读

### 当前读

读取的是当前最新版本，称为当前读；当前读不仅会对当前记录加行记录锁，还会对查询范围空间的数据加间隙锁


## MySQL 锁粒度划分

数据库锁定机制简单来说，就是数据库为了保证数据的一致性，而使各种共享资源在被并发访问变得有序所设计的一种规则

MySQL 各存储引擎使用了三种类型（级别）的锁定机制：表级锁定，行级锁定和页级锁定

- 表级锁定：各存储引擎中最大颗粒度的锁定机制；逻辑简单，带来的负面影响最小；获取锁和释放锁的速度很快；表级锁一次会将整个表锁定，可以很好的避免死锁问题；出现锁冲突的概率最高，致使并发度大打折扣

- 行级锁定：锁定颗粒度最小；发生锁冲突的概率最小，能够给予最大的并发处理能力；每次获取锁和释放锁消耗最大且加锁慢；最容易发生死锁；行锁只在 WHERE 主键时生效，非主键时都会锁全表

- 页级锁定：锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销介于二者之间；会出现死锁，并发度一般

||表锁|行锁|页锁|
|-|-|-|-|
MyISAM|√||
BDB|√||√|
InnoDB|√|√（默认）|√

## InnoDB 的行锁与表锁

InnoDB 行锁是通过给索引上的索引项加锁来实现的；只有通过索引条件检索数据，InnoDB 才使用行级锁，否则将使用表锁

由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，因此虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的(查询非唯一索引时，非唯一索引可能对应多条聚簇索引，因此会锁住多行)；当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行

即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同的执行计划的代价来决定的。如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁

## InnoDB 锁算法

### Record lock

单个行记录上的锁；当查询的索引含有唯一属性时，使用 record lock；RC 级别使用该方式加锁

- 使用聚簇索引等值查询

![wKZYTJ.png](https://s1.ax1x.com/2020/09/07/wKZYTJ.png)

- 使用唯一索引等值查询

![wKZaf1.png](https://s1.ax1x.com/2020/09/07/wKZaf1.png)

### Gap lock

间隙锁，锁定一个索引范围（左开右开），不包括记录本身；设计的目的是为了阻止多个事务将记录插入到同一范围内，防止幻读的产生

- 使用一般索引等值查询：不仅给相应索引和聚簇索引加 record lock，还要给索引间隙加 gap lock

![wKZDOO.png](https://s1.ax1x.com/2020/09/07/wKZDOO.png))

![wKZT0g.png](https://s1.ax1x.com/2020/09/07/wKZT0g.png)


- 无索引查询：将聚簇索引中的所有行以及间隙都锁起来，等于锁表了

![wKmfL8.png](https://s1.ax1x.com/2020/09/07/wKmfL8.png)


### Next-key lock

record+gap 锁定一个范围，并包含记录本身；对于行的查询使用 next-key lock，解决幻读问题；把查询出来的记录锁住，同时也会把该范围查询内的所有间隙空间也会锁住，再之它会把相邻的下一个区间也会锁住；当使用唯一索引且得到的结果只有 1 条则降级为 Record lock；RR 级别使用该方式加锁

![wAttSI.png](https://s1.ax1x.com/2020/09/04/wAttSI.png)

## 锁机制划分

三种锁都分为共享读锁和排他写锁

### 共享读锁

- 持有读锁的会话可以读表，但不能写表

- 允许多个会话同时持有读锁

- 其他会话就算没有给表加读锁，也是可以读表的，但是不能写表

- 其他会话申请该表写锁时会阻塞，直到锁释放

### 排他写锁

- 持有写锁的会话既可以读表，也可以写表

- 只有持有写锁的会话才可以访问该表，其他会话访问该表会被阻塞，直到锁释放

- 其他会话无论申请该表的读锁或写锁，都会阻塞，直到锁释放


## 隔离级别与锁

- 未提交读 READ UNCOMMITTED：读取数据不加共享锁

- 提交读 READ COMMITTED：读取数据加共享锁，操作结束后释放共享锁

- 可重复读 REPEATABLE READ：读取数据加共享锁，事务提交前不释放锁

- 可串行化 SERIALIZABLE：锁定整个范围的键并一直有锁，直到事务完成


## 乐观锁、悲观锁

- 乐观锁：假设不会发生并发冲突不会上锁，只在提交操作时检查是否违反数据完整性；适用于多读的应用类型，这样可以提高吞吐量

- 悲观锁：假定会发生并发冲突，每次在拿数据的时候都会上锁，屏蔽一切可能违反数据完整性的操作；

## 死锁

当多个进程访问同一数据库时，其中每个进程拥有的锁都是其他进程所需的，由此造成每个进程都无法继续下去；进程 A 等待进程 B 释放他的资源，B 又等待 A 释放他的资源，这样就互相等待就形成死锁

InnoDB 能检测到死锁的循环依赖并立即返回一个错误

解决方法：

- 尽量使用较低的隔离级别

- 设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会

- 显示加锁时，一次性请求足够级别的锁

- 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表

- 尽量用相等条件访问数据

- 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率

- 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率

- 用分布式事务锁或者使用乐观锁


## 表锁行锁与死锁

MyISAM 中是不会产生死锁的，因为 MyISAM 总是一次性获得所需的全部锁，要么全部满足，要么全部等待。而在 InnoDB 中，锁是逐步获得的，就造成了死锁的可能

InnoDB 行锁并不是直接锁数据而是锁索引；索引分为主键索引和非主键索引两种，如果一条 SQL 语句操作了主键索引，MySQL 就会锁定这条主键索引；如果一条 SQL 语句操作了非主键索引，MySQL 就会先锁定该非主键索引，再锁定相关的主键索引

当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引；另一个锁定了非主键索引，在等待主键索引，这样就会发生死锁


## MySQL 引擎

InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高，但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据，因此，主键不应该过大，否则其他索引也会很大；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的

InnoDB 支持外键，MyISAM 不支持外键

InnoDB 锁粒度是行锁，而 MyISAM 是表锁

InnoDB 支持事务，对于 InnoDB 每一条 SQL 语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条 SQL 语言放在 begin 和 commit 之间，组成一个事务；MyISAM 不支持事务，但可以在 service 层进行根据自己的业务需求进行相应的控制

InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表行数

InnoDB 支持 MVCC，MyISAM 不支持

InnoDB 和 MyISAM 都支持 B+ 树索引，InnoDB 还支持自适应哈希索引

MyISAM 实现了前缀压缩技术，占用存储空间更小（但会影响查找），InnoDB 是原始数据存储，占用存储更大

MyISAM 支持全文索引，InnoDB不支持全文索引，但可以通过插件实现


## MyISAM 表加锁方法

在执行查询语句前，会自动给涉及的表加读锁，在执行更新操作前，会自动给涉及的表加写锁

在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁

MyISAM 存储引擎支持并发插入，以减少的读和写操作之间的冲突：如果 MyISAM 表在数据文件中间没有空闲块，则行始终插入数据文件的末尾；可以在其他线程进行读操作的时候，同时将行插入到 MyISAM 表中；文件中间的空闲块可能是从表格中间删除或更新的行而产生的，如果文件中间有空闲块，则并发插入会被禁用，但是当所有空闲块都填充有新数据时，它又会自动重新启用


## InnoDB 加锁方式

对于普通 SELECT 语句，InnoDB 不会加任何锁；事务可以通过显式方式加共享锁或排他锁

对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB 会自动加排他锁

InnoDB 在事务执行过程中，使用两阶段锁协议：根据隔离级别在需要的时候自动加锁；在执行 commit 或者 rollback 的时候所有的锁在同一时刻被释放


## MyISAM 和 InnoDB 适合场景

### MyISAM

MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止

默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求；因此 MyISAM 适合于以读为主，不适合有大量更新操作，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞


### InnoDB

Innodb 适合于读写操作且频率高，要保证数据的完整性，并发量高，支持事务和外键的应用程序


## InnoDB 索引和 MyISAM 索引

- InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引

- InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效

- MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据

- InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效


## SQL 优化

- 在经常性的检索列上，建立必要索引，以加快搜索速率，避免全表扫描

- 多次查询同样的数据，可以考虑缓存该组数据

- 切分查询（大查询切分成为小查询，避免一次性锁住大量数据）

- 分解关联查询（单表查询，结果在应用程序中进行关联，可以减少处理过程中的锁争用）

- 尽量先做单表查询

- 当并发插入比较多时尽量使用等值查询，避免范围条件


## 子查询与关联查询

子查询就是查询中又嵌套的查询，表连接都可以用子查询替代，但不是所有子查询都能用表连接替换，子查询比较灵活，方便，形式多样，适合用于作为查询的筛选条件，而表连接更适合与查看多表的数据

子查询不一定需要两个表有关联字段，而连接查询必须有字段关联

对于数据量多的肯定是用连接查询快些，因为子查询会多次遍历所有的数据（视你的子查询的层次而定），而连接查询只会遍历一次

执行子查询时，MYSQL 需要创建临时表，查询完毕后再删除这些临时表，所以子查询的速度会受到一定的影响，这里多了一个创建和销毁临时表的过程；使用连接查询（JOIN）代替子查询，连接查询不需要建立临时表，因此其速度比子查询快

## 视图

视图是一种虚拟表，在物理上是不存在，其内容与真实的表相似，包含一系列带有名称的列和行数据

视图根本用途：简化 sql 查询，提高开发效率

### 特点

- 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系

- 视图的建立和删除不影响基本表

- 对视图内容的更新(添加，删除和修改)直接影响基本表

- 当视图来自多个基本表时，不允许添加和删除数据

### 优点

- 查询简单化

- 数据安全性

- 逻辑数据独立性

### 缺点

- 数据库必须把视图的查询转化成对基本表的查询，性能较差

- 修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改，因此带来修改限制


## 删除数据库

||Delete|Truncate|Drop|
|-|-|-|-|
回滚|可回滚|不可回滚|不可回滚|
删除内容|表结构还在，删除表的全部或一部分行|表结构还在，删除所有数据|删除表，数据、索引和权限都删除|
删除速度|慢，需逐行删除|快|最快|


## MySQL 查询缓存

MySQL 查询缓存是用来缓存特定 Query 的整个结果集信息，且共享给所有客户端，对查询语句进行 Hash 计算后，把得到的 hash 值与 Query 查询的结果集对应存放在 Query Cache 中；MySQL Server 会对接收到的每一个 SELECT 语句通过特定的 Hash 算法计算该 Query 的 Hash 值，然后通过该 hash 值到 Query Cache 中去匹配；如果通过 hash 值匹配到了一样的 Query，则直接将 cache 中相应的 Query 结果集返回给客户端；如果没有匹配，将这个 hash 值存放在一个 hash 链表中，并将 Query 的结果集存放到 cache 中，存放 hash 值链表的每个 hash 节点存放了相应 Query 结果集在 cache 中的地址，以及该 query 所涉及到一些 table 相关信息

MySQL 缓存机制简单的说就是缓存 sql 文本及查询结果，如果运行相同的 SQL，服务器直接从缓存中取到结果，而不需要再去解析和执行 SQL。如果表更改了，那么使用这个表的所有缓存查询将不再有效，查询缓存中值相关条目被清空

对于频繁更新的表，查询缓存是不适合的，而对于一些不常改变数据且有大量相同 SQL 查询的表，查询缓存会节约很大的性能

MySQL Query Cache 使用内存池技术，自己管理内存释放和分配，而不是通过操作系统。内存池使用的基本单位是变长的 block, 用来存储类型、大小、数据等信息；一个 result set 的 cache 通过链表把这些 block 串起来

MySQL Server 中打开 Query Cache 对数据库的读和写都会带来额外的消耗:

- 读查询开始之前必须检查是否命中缓存

- 如果读查询可以缓存，那么执行完查询操作后，会把查询结果和查询语句写入缓存

- 当向某个表写入数据的时候，必须将这个表所有的缓存设置为失效，如果缓存空间很大，则消耗也会很大

- 对 InnoDB 表，当修改一个表时，设置了缓存失效，但是多版本特性会暂时将这修改对其他事务屏蔽，在这个事务提交之前，所有查询都无法使用缓存，直到这个事务被提交，所以长时间的事务，会大大降低查询缓存的命中

## MySQL 查询缓存

### 机制

查询缓存用来缓存特定 Query 的整个结果集信息，且共享给所有客户端

对查询语句进行 Hash 计算后，把得到的 hash 值与 Query 查询的结果集对应存放在 Query Cache 中，目前 MySQL Query Cache 只会 cache select 语句

1. 如果没有匹配，将这个 hash 值存放在一个 hash 链表中，并将 Query 的结果集存放到 cache 中，存放 hash 值链表的每个 hash 节点存放了相应 Quey 结果集在 cache 中的地址，以及该 query 所涉及到一些 table 相关信息

2. 如果通过 hash 值匹配到了一样的 Query，则直接将 cache 中相应的 Query 结果集返回给客户端

### 命中条件

- 两个 SQL 语句，只要相差哪怕一个字符(例如大小写不一样，多一个空格，多注释)，那么这两个 SQL 将使用不同的 Cache 地址

- 如果表更改了，那么使用这个表的所有缓存查询将不再有效，查询缓存中值相关条目被清空；这里的更改指的是表中任何数据或是结构发生改变，包括 INSERT、UPDATE、 DELETE、TRUNCATE、ALTER TABLE、DROP TABLE 或 DROP DATABASE 等，也包括那些映射到改变了的表使用 MERGE 表的查询

- 当某个表正在写入数据，则这个表的缓存（命中缓存，缓存写入等）将会处于失效状态；在 Innodb 中，如果某个事务修改了这张表，则这个表的缓存在事务提交前都会处于失效状态，在这个事务提交前，这个表的相关查询都无法被缓存

- where 条件中如包含任何一个不确定的函数将永远不会被 cache, 比如 current_date, now 等

- 太大的 result set 不会被 cache (< query_cache_limit)

- 缓存清空的机制是目标表有任何更新操作，都会导致该表的所有缓存失效，而不能实现行级别的缓存清空；Serializable 情况下，所有查询语句都不能缓存

### 内存管理

MySQL Query Cache 使用内存池技术，自己管理内存释放和分配，而不是通过操作系统

query_cache_limit：可以缓存的单条查询的最大结果集的大小，默认值为 1MB

query_cache_min_res_unit：每次分配内存的最小空间大小，也就是用于缓存查询结果的最小内存空间的大小，默认值为 4KB

query_cache_size：可以使用的最大内存空间的大小，必须是 1024 的整数倍

1. 数据库启动时需要初始化查询缓存需要的内存，这时内存池是一个完整的空闲块，而这个空闲块的大小是 query_cache_size 的值减去用于维护元数据的数据结构所消耗的空间（约 40KB）

2. 当有查询结果需要缓存的时候，MySQL 先从大的空闲块中申请 query_cache_min_res_unit 大小的内存用于存储结果

3. MySQL 逐步向数据块写入数据，若数据块全部使用完成后仍然有剩余的数据需要存储，那么将再次向空闲空间申请一个数据块，直到数据全部存储完成

4. 当存储完成后申请的数据块还有部分剩余空间，那么这部分将被释放，并入到空闲内存部分

并发插入和缓存失效都会导致内存碎片

### 优缺点

优点：Query Cache 的查询，发生在 MySQL 接收到客户端的查询请求、查询权限验证之后和查询 SQL 解析之前；Query Cache是基于内存的，直接从内存中返回相应的查询结果，减少了大量的磁盘 I/O 和 CPU 计算，提高效率

缺点：

- 查询语句的 hash 计算和 hash 查找带来的资源消耗

- 如果表的变更比较频繁，则会造成 Query Cache 的失效率非常高

- 查询语句不同，但查询结果相同的查询都会被缓存，这样便会造成内存资源的过度消耗

- 内存碎片会导致 Query Cache 频繁清理内存

## 触发器

触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合，使用触发器可以保证某些操作之间的一致性

能决定触发器执行某个操作的事件有：insert、update 和 delete

不能在同一张表上建立 2 种同类型的触发器，一张表最多创建 6 个触发器(6 种类型)：即 BEFORE INSERT、BEFORE UPDATE、BEFORE DELETE、AFTER INSERT、AFTER UPDATE、AFTER DELETE

在 INSERT 型触发器中，NEW 用来表示将要（BEFORE）或已经（AFTER）插入的新数据

在 UPDATE 型触发器中，OLD 用来表示将要或已经被修改的原数据，NEW 用来表示将要或已经修改为的新数据

在 DELETE 型触发器中，OLD 用来表示将要或已经被删除的原数据

OLD 是只读的，而 NEW 则可以在触发器中使用 SET 赋值，这样不会再次触发触发器，造成循环调用

多个执行语句则用 BEGIN、END 包围

触发器基于行触发，当对整个表进行操作时效果较差

在基于锁的操作中，触发器可能会导致锁等待或死锁；触发器执行失败，原来执行的 SQL 语句也会执行失败

## 主从同步

为了减轻数据库压力，需要对数据库做读写分离和主从同步，写操作走主库，读操作走从库，分散了数据库的访问压力，提升整个系统的性能和可用性

![0NSOo9.png](https://s1.ax1x.com/2020/10/06/0NSOo9.png)

### 主从复制原理

主从复制需要三个线程，master（binlog dump thread）、slave（I/O thread 、SQL thread）

- master 库 binlog dump 线程：当主库中有数据更新时，会将此次更新的事件类型写入到主库的 binlog 文件中，此时主库会创建 log dump 线程通知 slave 有数据更新，当 I/O 线程请求日志内容时，会将此时的 binlog 名称和当前更新的位置同时传给 slave 的 I/O 线程

- slave 库 I/0 线程：该线程会连接到 master，向 log dump 线程请求一份指定 binlog 文件位置的副本，并将请求回来的 binlog 存到本地的 relay log 中

- slave 库 SQL 线程：该线程检测到 relay log 有更新后，会读取并在本地做 redo 操作，将发生在主库的事件在本地重新执行一遍，来保证主从数据同步；如果一个 relay log 文件中的全部事件都执行完毕，那么 SQL 线程会自动将该 relay log 文件删除掉

![0NCUZF.png](https://s1.ax1x.com/2020/10/06/0NCUZF.png)