# 内存管理

## 虚拟地址空间

为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，以及让程序获得更多可用内存，采用了虚拟内存

虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的内存；所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存

![wctV9e.png](https://s1.ax1x.com/2020/09/16/wctV9e.png)

在每个进程创建加载时，内核只是为进程创建了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好，等到运行到对应的程序时，才会通过缺页异常，来拷贝数据；进程运行过程中，要动态分配内存，比如 `malloc` 时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常

优点：

- 扩大地址空间

- 内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方；对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改

- 公平内存分配

- 当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存

缺点：

- 虚拟地址到物理地址的转换，增加了指令的执行时间

- 页面的换入换出需要磁盘 I/O，非常耗时

## 内存分页

分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小，在 Linux 下，每一页的大小为 4KB

![wcNVaV.png](https://s1.ax1x.com/2020/09/16/wcNVaV.png)

页表实际上存储在 CPU 的内存管理单元 （MMU） 中，于是 CPU 就可以直接通过 MMU，找出要实际要访问的物理内存地址

当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行

采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存

如果内存空间不够，操作系统会把其他正在运行的进程中的最近没被使用的内存页面给释放掉，
也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，
称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，
不会花太多时间，内存交换的效率就相对比较高

分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去

在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址

![wcUQfS.png](https://s1.ax1x.com/2020/09/16/wcUQfS.png)

内存地址转换步骤：

- 把虚拟内存地址，切分成页号和偏移量

- 根据页号，从页表里面，查询对应的物理页号

- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址

![0A1r24.png](https://s1.ax1x.com/2020/09/27/0A1r24.png)

单级分页导致页表占用内存过大，后采用多级页表，64 位系统需要四级页表

## 缺页中断

`malloc()` 和 `mmap()` 等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存；当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常

缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存


## 进程的内存结构

每个进程所分配的内存由很多部分组成，通常称之为段

![d1x0Ve.png](https://s1.ax1x.com/2020/08/19/d1x0Ve.png)

### 文本段 （text 段）

- 包含了进程运行的程序机器语言指令

- 文本段具有只读属性，以防止进程通过错误指针意外修改自身指令

- 因为多个进程可同时运行同一程序，所以又将文本段设为可共享，一份程序代码的拷贝可以映射到所有这些进程的虚拟地址空间中

### 初始化的数据段（data 段）

- 包含显式初始化的全局变量和静态变量

- 当程序加载到内存时，从可执行文件中读取这些变量的值

### 未初始化数据段（BSS 段）

- 包含了未进行显式初始化的全局变量和静态变量

- 程序启动之前，系统将本段内所有内存初始化为 0

- 程序结束后静态变量资源由系统自动释放

- 将经过初始化的全局变量和静态变量与未初始化的全局变量和静态变量分开存放，其主要原因在于程序在磁盘上存储时，没有必要为未经初始化的变量分配存储空间；可执行文件只需记录未初始化数据段的位置及所需大小，直到运行时再由程序加载器来分配空间

### 堆

- 可在运行时为变量动态进行内存分配的一块区域

- 从低地址位向高地址位增长，采用链式存储结构

### 栈

- 一个动态增长和收缩的段，由栈帧组成

- 从高地址位向低地址位增长的，是一块连续的内存区域，最大容量是由系统预先定义好的，用户能从栈中获取的空间较小

- 系统会为每个当前调用的函数分配一个栈帧

## 包含 static、virtual 的类内存分布

- `static` 修饰成员变量在全局数据区分配内存

- `static` 修饰的成员函数在代码区分配内存

- 虚指针和该类其他成员一起存储，指向只读数据段中的类虚函数表，虚函数表中存放着一个个函数指针，函数指针指向代码段中的具体函数，虚函数表存储在 data 段的只读数据段

![d8cscq.png](https://s1.ax1x.com/2020/08/20/d8cscq.png)


## 堆内存分配

C 标准函数库提供了许多函数来实现对堆上内存管理，其中包括：`malloc()`、`free()`、`calloc()` 和 `realloc()`

### malloc()

```cpp
void * malloc(size_t n);

void * memset (void * p, int c, size_t n);
```

如果函数执行成功，`malloc()` 返回获得内存空间的首地址；如果函数执行失败，那么返回值为 `NULL`。由于 `malloc()` 函数值的类型为 `void*`，因此可以将其值类型转换后赋给任意类型指针，这样就可以通过操作该类型指针来操作从堆上获得的内存空间

`malloc()` 分配得到的内存空间是未初始化的，一般在使用该内存空间时要调用另一个函数 `memset()` 来将其初始化为全 0

### calloc()

`calloc()` 的功能与 `malloc()` 的功能相似，都是从堆分配内存

```cpp
void *calloc(size_t n, size_t size);
```

函数返回值为 `void*`，如果执行成功函数从堆上获得 size * n 的字节空间，并返回该空间的首地址，如果执行失败，函数返回 `NULL`；`calloc()` 适合为数组申请空间，可以将 size 设置为数组元素的空间长度，将 n 设置为数组的容量

`calloc()` 得到的内存空间是经过初始化的，其内容全为 0

### realloc()

`realloc()` 可以实现内存分配和内存释放的功能

```cpp
void * realloc(void * p, size_t n);
```

指针 p 必须为指向堆内存空间的指针，即由 `malloc()`、`calloc()` 或 `realloc()` 分配空间的指针

`realloc()`将指针 p 指向的内存块的大小改变为 n 字节，如果 n 小于或等于 p 之前指向的空间大小，那么保持原有状态不变；如果 n 大于原来 p 之前指向的空间大小，那么系统将重新为 p 从堆上分配一块大小为 n 的内存空间，同时将原来指向空间的内容依次复制到新的内存空间上，p 之前指向的空间被释放

`realloc()`分配的空间也是未初始化的

`realloc()` 有可能操作失败，返回 `NULL`，所以不要把它的返回值直接赋值给原来的指针变量，以免原值丢失

### free()

```cpp
void free(void * p);
```

`free()` 只是释放指针指向的内容，而该指针仍然指向原来指向的地方，此时指针为野指针


## 内存替换算法

常见的内存替换算法有：FIFO，LRU，LFU，LRU-K，2Q

- FIFO：最近刚访问的，将来访问的可能性比较大；使用一个队列，新加入的页面放入队尾，每次淘汰队首的页面，即最先进入的数据，最先被淘汰；无法体现页面冷热信息

- LFU：如果数据过去被访问多次，那么将来被访问的频率也更高；每个数据块一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序，每次淘汰队尾数据块；产生排序开销；缓存颠簸

- LRU：如果数据最近被访问过，那么将来被访问的几率也更高，淘汰最长时间没有被访问的数据；使用一个栈，新使用过的数据放动到栈顶，每次替换栈顶的缓存数据

- LRU-K：最久未使用 K 次淘汰算法，K 代表最近使用的次数，因此 LRU 可以认为是 LRU-1

## LRU 实现

- 新数据直接插入到列表头部

- 缓存数据被命中，将数据移动到列表头部

- 缓存已满的时候，移除列表尾部数据

LRU 算法需要添加头节点，删除尾结点

链表添加节点/删除节点时间复杂度 O(1)，非常适合当做存储缓存数据容器，但链表有几个缺点：每次获取任意节点数据，都需要从头结点遍历下去，这就导致获取节点复杂度为 O(N)；移动中间节点到头结点，我们需要知道中间节点前一个节点的信息，单向链表就不得不再次遍历获取信息

使用散列表存储节点，获取节点的复杂度将会降低为 O(1)，节点移动问题可以在节点中再增加前驱指针，记录上一个节点信息，这样链表就从单向链表变成了双向链表

![wzvl38.png](https://s1.ax1x.com/2020/09/24/wzvl38.png)

```cpp
class LRUCache {
private:
    unordered_map<int, list<pair<int, int>>::iterator> lru;
    list<pair<int, int>> his;
    int cap;
    
public:
    LRUCache(int capacity) {
        cap = capacity;
    }
    
    int get(int key) {
        if(lru.count(key) != 0) {
            his.splice(his.begin(), his, lru[key]);
            return lru[key]->second;
        }
        return -1;
    }
    
    void put(int key, int value) {
        if(lru.count(key)) his.erase(lru[key]);
        his.push_front(make_pair(key, value));
        lru[key] = his.begin();
        if(lru.size() > cap) {
            lru.erase(his.rbegin()->first);
            his.pop_back();
        }
    }
};
```

## 内存溢出、内存泄露

### 内存溢出

程序申请内存时，没有足够的内存供申请者使用

可能原因：内存中加载的数据量过于庞大；代码中存在死循环或循环产生过多重复的对象实体；BUG

### 内存泄露

由于疏忽或错误造成了程序未能释放掉不再使用的内存

- 堆内存泄露：程序运行中根据需要通过 `new`、`malloc` 等从堆中分配的内存在使用完之后没有释放掉，导致程序运行过程中这片内存不会被再使用

- 系统资源泄露：程序使用系统分配的资源，如 `socket`、`handle` 等没有使用完后释放，导致系统资源浪费，严重可导致系统效能降低，系统运行不稳定

- 没有将基类的析构函数定义为虚函数